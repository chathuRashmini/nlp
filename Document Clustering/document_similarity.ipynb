{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec833059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from normalization import normalize_corpus\n",
    "from utils import build_feature_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab55eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A toy corpus (collection of documents) to explore the ideas\n",
    "toy_corpus = [\n",
    "    'The sky is blue',\n",
    "    'The sky is blue and beautiful',\n",
    "    'Look at the bright blue sky!',\n",
    "    'Python is a great Programming language',\n",
    "    'Python and Java are popular Programming languages',\n",
    "    'Among Programming languages, both Python and Java are the most used in Analytics',\n",
    "    'The fox is quicker than the lazy dog',\n",
    "    'The dog is smarter than the fox',\n",
    "    'The dog, fox and cat are good friends'\n",
    "]\n",
    "\n",
    "\n",
    "# Documents that we will be measuring similarities for\n",
    "query_docs = [\n",
    "    'The fox is definitely smarter than the dog',\n",
    "    'Java is a static typed programming language unlike Python',\n",
    "    'I love to relax under the beautiful blue sky!'\n",
    "]  \n",
    "\n",
    "\n",
    "# normalize and extract features from the toy corpus\n",
    "norm_corpus = normalize_corpus(toy_corpus, lemmatize=True)\n",
    "\n",
    "tfidf_vectorizer, tfidf_features = build_feature_matrix(norm_corpus,\n",
    "                                                        feature_type='tfidf',\n",
    "                                                        ngram_range=(1, 1), \n",
    "                                                        min_df=0.0, max_df=1.0)\n",
    "\n",
    "\n",
    "# normalize and extract features from the query corpus\n",
    "norm_query_docs =  normalize_corpus(query_docs, lemmatize=True) \n",
    "\n",
    "\n",
    "# Use the same vectorizer that was used to build the feature matrix for the corpus also for query doc         \n",
    "query_docs_tfidf = tfidf_vectorizer.transform(norm_query_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "616ec2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(doc_features, corpus_features, top_n=3):\n",
    "    \n",
    "    # Get document vectors\n",
    "    doc_features = doc_features[0]\n",
    "    \n",
    "    # Compute similarities by calling dot.product on transposed corpus feature vector\n",
    "    similarity = np.dot(doc_features, \n",
    "                        corpus_features.T)\n",
    "    similarity = similarity.toarray()[0]\n",
    "    \n",
    "    # Get docs with highest similarity scores\n",
    "    top_docs = similarity.argsort()[::-1][:top_n]\n",
    "    top_docs_with_score = [(index, round(similarity[index], 3))\n",
    "                            for index in top_docs]\n",
    "    return top_docs_with_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d5265a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Similarity Analysis using Cosine Similarity\n",
      "============================================================\n",
      "Document 1 : The fox is definitely smarter than the dog\n",
      "Top 3 similar docs:\n",
      "----------------------------------------\n",
      "Doc num: 8 Similarity Score: 1.0\n",
      "Doc: The dog is smarter than the fox\n",
      "----------------------------------------\n",
      "Doc num: 7 Similarity Score: 0.426\n",
      "Doc: The fox is quicker than the lazy dog\n",
      "----------------------------------------\n",
      "Doc num: 9 Similarity Score: 0.37\n",
      "Doc: The dog, fox and cat are good friends\n",
      "----------------------------------------\n",
      "\n",
      "Document 2 : Java is a static typed programming language unlike Python\n",
      "Top 3 similar docs:\n",
      "----------------------------------------\n",
      "Doc num: 5 Similarity Score: 0.733\n",
      "Doc: Python and Java are popular Programming languages\n",
      "----------------------------------------\n",
      "Doc num: 6 Similarity Score: 0.58\n",
      "Doc: Among Programming languages, both Python and Java are the most used in Analytics\n",
      "----------------------------------------\n",
      "Doc num: 4 Similarity Score: 0.498\n",
      "Doc: Python is a great Programming language\n",
      "----------------------------------------\n",
      "\n",
      "Document 3 : I love to relax under the beautiful blue sky!\n",
      "Top 3 similar docs:\n",
      "----------------------------------------\n",
      "Doc num: 2 Similarity Score: 1.0\n",
      "Doc: The sky is blue and beautiful\n",
      "----------------------------------------\n",
      "Doc num: 1 Similarity Score: 0.72\n",
      "Doc: The sky is blue\n",
      "----------------------------------------\n",
      "Doc num: 3 Similarity Score: 0.426\n",
      "Doc: Look at the bright blue sky!\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get Cosine similarity results for our example documents\n",
    "print('Document Similarity Analysis using Cosine Similarity')\n",
    "print('='*60)\n",
    "\n",
    "for index, doc in enumerate(query_docs):\n",
    "    \n",
    "    doc_tfidf = query_docs_tfidf[index]\n",
    "    top_similar_docs = compute_cosine_similarity(doc_tfidf,\n",
    "                                             tfidf_features,\n",
    "                                             top_n=3)\n",
    "    print('Document',index+1 ,':', doc)\n",
    "    print('Top', len(top_similar_docs), 'similar docs:')\n",
    "    print('-'*40)\n",
    "    \n",
    "    for doc_index, sim_score in top_similar_docs:\n",
    "        print('Doc num: {} Similarity Score: {}\\nDoc: {}'.format(doc_index+1, sim_score, toy_corpus[doc_index]))\n",
    "        print('-'*40)    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfbd7595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hellinger_bhattacharya_distance(doc_features, corpus_features,\n",
    "                                            top_n=3):                                        \n",
    "    # Get document vectors                                            \n",
    "    doc_features = doc_features.toarray()[0]\n",
    "    \n",
    "    corpus_features = corpus_features.toarray()\n",
    "    \n",
    "    # Compute HB distances\n",
    "    distance = np.hstack(\n",
    "                    np.sqrt(0.5 *\n",
    "                            np.sum(\n",
    "                                np.square(np.sqrt(doc_features) - \n",
    "                                          np.sqrt(corpus_features)), \n",
    "                                axis=1)))                        \n",
    "    \n",
    "    # Get docs with lowest distance scores                            \n",
    "    top_docs = distance.argsort()[:top_n]\n",
    "    top_docs_with_score = [(index, round(distance[index], 3))\n",
    "                            for index in top_docs]\n",
    "    return top_docs_with_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79cd9a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Similarity Analysis using Hellinger-Bhattacharya distance\n",
      "============================================================\n",
      "Document 1 : The fox is definitely smarter than the dog\n",
      "Top 3 similar docs:\n",
      "----------------------------------------\n",
      "Doc num: 8 Distance Score: 0.0\n",
      "Doc: The dog is smarter than the fox\n",
      "----------------------------------------\n",
      "Doc num: 7 Distance Score: 0.96\n",
      "Doc: The fox is quicker than the lazy dog\n",
      "----------------------------------------\n",
      "Doc num: 9 Distance Score: 1.05\n",
      "Doc: The dog, fox and cat are good friends\n",
      "----------------------------------------\n",
      "\n",
      "Document 2 : Java is a static typed programming language unlike Python\n",
      "Top 3 similar docs:\n",
      "----------------------------------------\n",
      "Doc num: 5 Distance Score: 0.702\n",
      "Doc: Python and Java are popular Programming languages\n",
      "----------------------------------------\n",
      "Doc num: 4 Distance Score: 0.925\n",
      "Doc: Python is a great Programming language\n",
      "----------------------------------------\n",
      "Doc num: 6 Distance Score: 0.926\n",
      "Doc: Among Programming languages, both Python and Java are the most used in Analytics\n",
      "----------------------------------------\n",
      "\n",
      "Document 3 : I love to relax under the beautiful blue sky!\n",
      "Top 3 similar docs:\n",
      "----------------------------------------\n",
      "Doc num: 2 Distance Score: 0.0\n",
      "Doc: The sky is blue and beautiful\n",
      "----------------------------------------\n",
      "Doc num: 1 Distance Score: 0.602\n",
      "Doc: The sky is blue\n",
      "----------------------------------------\n",
      "Doc num: 3 Distance Score: 0.96\n",
      "Doc: Look at the bright blue sky!\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get Hellinger-Bhattacharya distance based similarities for our example\n",
    "print('Document Similarity Analysis using Hellinger-Bhattacharya distance')\n",
    "print('='*60)\n",
    "\n",
    "for index, doc in enumerate(query_docs):\n",
    "    \n",
    "    doc_tfidf = query_docs_tfidf[index]\n",
    "    top_similar_docs = compute_hellinger_bhattacharya_distance(doc_tfidf,\n",
    "                                             tfidf_features,\n",
    "                                             top_n=3)\n",
    "    print('Document',index+1 ,':', doc)\n",
    "    print('Top', len(top_similar_docs), 'similar docs:')\n",
    "    print('-'*40)\n",
    "    for doc_index, sim_score in top_similar_docs:\n",
    "        print('Doc num: {} Distance Score: {}\\nDoc: {}'.format(doc_index+1,\n",
    "                                                                 sim_score,\n",
    "                                                                 toy_corpus[doc_index]))\n",
    "        print('-'*40)\n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9f5f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp \n",
    "\n",
    "def compute_corpus_term_idfs(corpus_features, norm_corpus):\n",
    "    \n",
    "    dfs = np.diff(sp.csc_matrix(corpus_features, copy=True).indptr)\n",
    "    dfs = 1 + dfs # to smoothen idf later\n",
    "    total_docs = 1 + len(norm_corpus)\n",
    "    idfs = 1.0 + np.log(float(total_docs) / dfs)\n",
    "    return idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8fcba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bm25_similarity(doc_features, corpus_features,\n",
    "                            corpus_doc_lengths, avg_doc_length,\n",
    "                            term_idfs, k1=1.5, b=0.75, top_n=3):\n",
    "    # Get corpus bag of words features\n",
    "    corpus_features = corpus_features.toarray()\n",
    "    \n",
    "    # convert query document features to binary features\n",
    "    # this is to keep a note of which terms exist per document\n",
    "    doc_features = doc_features.toarray()[0]\n",
    "    doc_features[doc_features >= 1] = 1\n",
    "    \n",
    "    # Compute the document idf scores for present terms\n",
    "    doc_idfs = doc_features * term_idfs\n",
    "    \n",
    "    # compute numerator expression in BM25 equation\n",
    "    numerator_coeff = corpus_features * (k1 + 1)\n",
    "    numerator = np.multiply(doc_idfs, numerator_coeff)\n",
    "    \n",
    "    # Compute denominator expression in BM25 equation\n",
    "    denominator_coeff =  k1 * (1 - b + \n",
    "                                (b * (corpus_doc_lengths / \n",
    "                                        avg_doc_length)))\n",
    "    denominator_coeff = np.vstack(denominator_coeff)\n",
    "    denominator = corpus_features + denominator_coeff\n",
    "    \n",
    "    # Compute the BM25 score combining the above equations\n",
    "    bm25_scores = np.sum(np.divide(numerator,\n",
    "                                   denominator),\n",
    "                         axis=1)\n",
    "    \n",
    "    # Get top n relevant docs with highest BM25 score                     \n",
    "    top_docs = bm25_scores.argsort()[::-1][:top_n]\n",
    "    top_docs_with_score = [(index, round(bm25_scores[index], 3))\n",
    "                            for index in top_docs]\n",
    "    return top_docs_with_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9179517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build bag of words based features first\n",
    "vectorizer, corpus_features = build_feature_matrix(norm_corpus,\n",
    "                                                   feature_type='frequency')\n",
    "\n",
    "# We use the same vectorizer that we used to build the feature matrix for the corpus also for query doc\n",
    "query_docs_features = vectorizer.transform(norm_query_docs)\n",
    "\n",
    "# Get average document length of the corpus (avgdl)\n",
    "doc_lengths = [len(doc.split()) for doc in norm_corpus]   \n",
    "avg_dl = np.average(doc_lengths) \n",
    "\n",
    "# Get the corpus term idfs\n",
    "corpus_term_idfs = compute_corpus_term_idfs(corpus_features,\n",
    "                                            norm_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "013831ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Similarity Analysis using BM25\n",
      "============================================================\n",
      "Document 1 : The fox is definitely smarter than the dog\n",
      "Top 3 similar docs:\n",
      "----------------------------------------\n",
      "Doc num: 8 BM25 Score: 7.334\n",
      "Doc: The dog is smarter than the fox\n",
      "----------------------------------------\n",
      "Doc num: 7 BM25 Score: 3.88\n",
      "Doc: The fox is quicker than the lazy dog\n",
      "----------------------------------------\n",
      "Doc num: 9 BM25 Score: 3.493\n",
      "Doc: The dog, fox and cat are good friends\n",
      "----------------------------------------\n",
      "\n",
      "Document 2 : Java is a static typed programming language unlike Python\n",
      "Top 3 similar docs:\n",
      "----------------------------------------\n",
      "Doc num: 5 BM25 Score: 5.501\n",
      "Doc: Python and Java are popular Programming languages\n",
      "----------------------------------------\n",
      "Doc num: 6 BM25 Score: 4.586\n",
      "Doc: Among Programming languages, both Python and Java are the most used in Analytics\n",
      "----------------------------------------\n",
      "Doc num: 4 BM25 Score: 3.88\n",
      "Doc: Python is a great Programming language\n",
      "----------------------------------------\n",
      "\n",
      "Document 3 : I love to relax under the beautiful blue sky!\n",
      "Top 3 similar docs:\n",
      "----------------------------------------\n",
      "Doc num: 2 BM25 Score: 7.334\n",
      "Doc: The sky is blue and beautiful\n",
      "----------------------------------------\n",
      "Doc num: 1 BM25 Score: 4.984\n",
      "Doc: The sky is blue\n",
      "----------------------------------------\n",
      "Doc num: 3 BM25 Score: 3.88\n",
      "Doc: Look at the bright blue sky!\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze document similarity using BM25 framework    \n",
    "print('Document Similarity Analysis using BM25')\n",
    "print('='*60)\n",
    "\n",
    "for index, doc in enumerate(query_docs):\n",
    "    \n",
    "    doc_features = query_docs_features[index]\n",
    "    top_similar_docs = compute_bm25_similarity(doc_features,\n",
    "                                               corpus_features,\n",
    "                                               doc_lengths,\n",
    "                                               avg_dl,\n",
    "                                               corpus_term_idfs,\n",
    "                                               k1=1.5, b=0.75,\n",
    "                                               top_n=3)\n",
    "    print('Document',index+1 ,':', doc)\n",
    "    print('Top', len(top_similar_docs), 'similar docs:')\n",
    "    print('-'*40)\n",
    "    for doc_index, sim_score in top_similar_docs:\n",
    "        print('Doc num: {} BM25 Score: {}\\nDoc: {}'.format(doc_index+1,\n",
    "                                                                 sim_score,\n",
    "                                                                 toy_corpus[doc_index])) \n",
    "        print('-'*40)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
